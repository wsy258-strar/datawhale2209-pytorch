{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc0ed72",
   "metadata": {},
   "source": [
    "# 2.1神经网络学习机制\n",
    "- 数据预处理\n",
    "- 模型设计\n",
    "- 损失函数和优化方案设计\n",
    "- 前向传播\n",
    "- 反向传播\n",
    "- 更新参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15ef8e",
   "metadata": {},
   "source": [
    "# 2.2深度学习在实现上的特殊性\n",
    "- 样本量大，通常需要分批（batch）加载\n",
    "- 逐层、模块化搭建网络（卷积层、全连接层、LSTM等）\n",
    "- 多样化的损失函数和优化设计\n",
    "- GPU的使用(并行计算）\n",
    "- 以上各个模块之间的配合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0866b",
   "metadata": {},
   "source": [
    "# 2.3PyTorch深度学习模块\n",
    "- 基本配置\n",
    "- 数据读入\n",
    "- 模型构建\n",
    "- 损失函数\n",
    "- 优化器\n",
    "- 训练与评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d4417",
   "metadata": {},
   "source": [
    "## FashionMNIST时装分类\n",
    "- 十类图片\n",
    "- 32*32px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765d26c",
   "metadata": {},
   "source": [
    "### 基本配置\n",
    "- 导入必要的packages：os、numpy、torch、torch.nn、torch.optim、torch.utils.data\n",
    "- 配置训练过程的超参数：batch_size、learning_rate、max_epochs、num_workers\n",
    "- 配置训练用的硬件设备：CPU or GPU、which GPU(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43157531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2630f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#配置GPU\n",
    "##方案一：使用os.environ\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#方案二：使用“device”,后续要对使用的GPU的变量用.to(device)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "##配置其他超参数\n",
    "batch_size = 256\n",
    "num_workers = 4 #有多少个线程共cpu读入数据\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd6419",
   "metadata": {},
   "source": [
    "### 数据读入和加载\n",
    "- 如何读取个数不定的本地数据：Dataset：__init__,__getitem__,__len__\n",
    "- 如何将数据加载以供模型读入：DataLoader：batch_size,num_workers,shuffle,drop_last,pin_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e2cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先设置数据变换\n",
    "from torchvision import transforms\n",
    "\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),  #第一步取决于后续的数据读取方式，如果使用内置的数据集则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da929120",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式一：使用torchvision自带的数据集，下载可能需要一些时间\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.FashionMNIST(root = './',train = True,download = True,transform = data_transform)\n",
    "test_data = datasets.FashionMNIST(root = './',train = False,download = True,transform = data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d84cfbe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_181/4038528335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# test_df = pd.read_csv('./FashionMNIST/fashion-mnist_test.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#FMDataset实例化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFMDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFMDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "## 读取方式二： 读入csv格式的数据，自行构建Dataset类\n",
    "# csv数据下载链接：https;//www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self,df,trandform = None):\n",
    "        self.df = df\n",
    "        self.trandform = trandform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:,0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,idx): #将csv每行的值转变为28*28*1的图片\n",
    "        image = self.images[idx].reshape(28,28,1) #强行加一个通道数\n",
    "        label = int(self.labels[idx])\n",
    "        if trandform is not None:\n",
    "            image = self.trandform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255.,dtype = torch.float)\n",
    "        label = torch.tensor(label,dtype = torch.long)\n",
    "        return image,label\n",
    "train_df = pd.read_csv('./FashionMNIST/fashion-mnist_train.csv')\n",
    "test_df = pd.read_csv('./FashionMNIST/fashion-mnist_test.csv')\n",
    "#FMDataset实例化\n",
    "train_data = FMDataset(train_df,data_transform)\n",
    "test_data = FMDataset(test_df,data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe4025",
   "metadata": {},
   "source": [
    "- 在构建训练集和测试集完成后，需要定义DataLoader类，以便在训练和测试时加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f50b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size = batch_size,shuffle = True,num_workers = num_workers,drop_last = True)#是否读取最后一个数据，树模型通常不用最后一个数据\n",
    "test_loader = DataLoader(test_data,batch_size = batch_size,shuffle = False,num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160bb2d1",
   "metadata": {},
   "source": [
    "- pin_memory ：可以让程序运行的更快，拿空间换时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd2659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (3.5.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from matplotlib) (4.37.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (4.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/wsy/miniconda3/envs/openvivo_env_py37/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cf143cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6198aa7550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#读入数据进行可视化操作，验证数据读入是否正确\n",
    "import matplotlib.pyplot as plt\n",
    "image,label = next(iter(train_loader)) #不断向下迭代数据\n",
    "print(image.shape,label.shape) #256：batch_size的大小\n",
    "plt.imshow(image[0][0],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2abadd",
   "metadata": {},
   "source": [
    "### 模型构建\n",
    "- 神经网络的构建：基于nn.Model（__init__,forward）\n",
    "- 神经网络是通过“层定义+层顺序”的方式构建起来的\n",
    "- 神经网络常见层：nn.Conv2d,nn.MaxPool2d,nn.Linear,nn.ReLU,... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a14eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型设计：手搭CNN，用GPU进行训练\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv = nn.Sequential( #惯序模型：已经有网络层的顺序\n",
    "            nn.Conv2d(1,32,5),\n",
    "            nn.ReLU(), #激活函数\n",
    "            nn.MaxPool2d(2,stride=2),#池化\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32,64,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride = 2),\n",
    "            nn.Dropout(0.3)\n",
    "#             Dropout是指在模型训练时随机让网络某些隐含层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，\n",
    "#             但是它的权重得保留下来（只是暂时不更新而已），因为下次样本输入时它可能又得工作了。   \n",
    "#             训练神经网络模型时，如果训练样本较少，为了防止模型过拟合，Dropout可以作为一种trikc供选择。\n",
    "        )\n",
    "        #全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4,512), #从64*4*4的神经元到512个神经元\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10) #10类图片\n",
    "        )\n",
    "    def forward(self,x): #前馈\n",
    "        x = self.conv(x) #输入卷积层\n",
    "        x = x.view(-1,64*4*4) #维度变换，拉直操作\n",
    "        x = self.fc(x) #64*4*4维的数据变为10维进行输出\n",
    "        \n",
    "        return x\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "# model = nn.DataParallel(model).cuda() #多卡训练时的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae48cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e8e16c",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "- torch.nn提供了多种预定义的损失函数\n",
    "- 可以自己定义损失函数\n",
    "- 根据实际需求选取对应的损失函数\n",
    "- 损失函数常用操作：backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d08d8b",
   "metadata": {},
   "source": [
    "### 设定损失函数\n",
    "- 使用torch.nn模块自带的CrossEntropy损失\n",
    "- pytorch会自动把整数型的label转换为one-hot型，用于计算CE loss\n",
    "- 这里需要确保label是从0开始，同时模型不加softmax层(使用logits计算)，这也说明了pytorch训练中各个部分不是独立的，需要通盘考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11237caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#可以给不同类加权重\n",
    "# criterion = nn.CrossEntropyLoss(weight = [1,1,1,1,3,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316fb8a",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "- torch.optim提供了多种预定义的优化器\n",
    "- 可以自己定义优化器\n",
    "- 根据实际需求选取对应的损失函数\n",
    "- 优化器常用操作： step(),zero_grad(),load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220c73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam优化器\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5a6c7",
   "metadata": {},
   "source": [
    "### 训练与评估\n",
    "- 模型状态设置：model.train(),model.eval()\n",
    "- 训练流程：读取、转换、梯度清零、输入、计算损失、反向传播、参数更新\n",
    "- 验证流程：读取、转换、输入、计算损失、计算指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc6b4a",
   "metadata": {},
   "source": [
    "### 训练和测试（验证）\n",
    "两者的区别：\n",
    "- 模型状态设置\n",
    "- 是否需要初始化优化器\n",
    "- 是否需要将loss传回网络\n",
    "- 是否需要每步更新optimizer\n",
    "此外，对于测试或者验证，可以计算分类准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de741a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data,label in train_loader:\n",
    "        data,label = data.cuda(),label.cuda()\n",
    "        optimizer.zero_grad() #梯队会累加，所以梯度回传不需要累加\n",
    "        output = model(data)\n",
    "        loss = criterion(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step() #更新权重\n",
    "        train_loss += loss.item()*data.size(0) #训练损失的叠加\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch,train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81542697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad(): #不做梯度的计算，不存在梯度，所以不需要清零\n",
    "        for data,label in test_loader:\n",
    "            data,label = data.cuda(),label.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output,1) #\n",
    "            gt_labels.append(label.cpu().data.numpy())\n",
    "            pred_labels.append(preds.cpu().data.numpy())\n",
    "            loss = criterion(output,label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "    val_loss = val_loss/len(test_loader.dataset)\n",
    "    gt_labels,pred_labels = np.concatenate(gt_labels),np.concatenate(pred_labels)\n",
    "    acc = np.sum(gt_labels == pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f},Accuracy: {:.6f}'.format(epoch,val_loss,acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5241416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.652716\n",
      "Epoch: 1 \tValidation Loss: 0.443665,Accuracy: 0.837600\n",
      "Epoch: 2 \tTraining Loss: 0.413911\n",
      "Epoch: 2 \tValidation Loss: 0.357751,Accuracy: 0.871700\n",
      "Epoch: 3 \tTraining Loss: 0.354646\n",
      "Epoch: 3 \tValidation Loss: 0.321965,Accuracy: 0.883600\n",
      "Epoch: 4 \tTraining Loss: 0.319467\n",
      "Epoch: 4 \tValidation Loss: 0.298579,Accuracy: 0.890300\n",
      "Epoch: 5 \tTraining Loss: 0.296765\n",
      "Epoch: 5 \tValidation Loss: 0.292735,Accuracy: 0.894800\n",
      "Epoch: 6 \tTraining Loss: 0.280536\n",
      "Epoch: 6 \tValidation Loss: 0.277010,Accuracy: 0.901600\n",
      "Epoch: 7 \tTraining Loss: 0.265045\n",
      "Epoch: 7 \tValidation Loss: 0.271075,Accuracy: 0.904400\n",
      "Epoch: 8 \tTraining Loss: 0.258741\n",
      "Epoch: 8 \tValidation Loss: 0.263781,Accuracy: 0.904200\n",
      "Epoch: 9 \tTraining Loss: 0.248359\n",
      "Epoch: 9 \tValidation Loss: 0.250519,Accuracy: 0.907700\n",
      "Epoch: 10 \tTraining Loss: 0.234053\n",
      "Epoch: 10 \tValidation Loss: 0.241821,Accuracy: 0.912800\n",
      "Epoch: 11 \tTraining Loss: 0.226389\n",
      "Epoch: 11 \tValidation Loss: 0.238854,Accuracy: 0.913700\n",
      "Epoch: 12 \tTraining Loss: 0.219235\n",
      "Epoch: 12 \tValidation Loss: 0.243975,Accuracy: 0.908300\n",
      "Epoch: 13 \tTraining Loss: 0.210296\n",
      "Epoch: 13 \tValidation Loss: 0.233690,Accuracy: 0.917500\n",
      "Epoch: 14 \tTraining Loss: 0.203361\n",
      "Epoch: 14 \tValidation Loss: 0.227733,Accuracy: 0.917000\n",
      "Epoch: 15 \tTraining Loss: 0.199097\n",
      "Epoch: 15 \tValidation Loss: 0.226273,Accuracy: 0.915400\n",
      "Epoch: 16 \tTraining Loss: 0.193585\n",
      "Epoch: 16 \tValidation Loss: 0.225662,Accuracy: 0.915900\n",
      "Epoch: 17 \tTraining Loss: 0.188119\n",
      "Epoch: 17 \tValidation Loss: 0.226206,Accuracy: 0.916900\n",
      "Epoch: 18 \tTraining Loss: 0.181853\n",
      "Epoch: 18 \tValidation Loss: 0.236549,Accuracy: 0.913300\n",
      "Epoch: 19 \tTraining Loss: 0.179298\n",
      "Epoch: 19 \tValidation Loss: 0.230088,Accuracy: 0.916300\n",
      "Epoch: 20 \tTraining Loss: 0.173322\n",
      "Epoch: 20 \tValidation Loss: 0.224085,Accuracy: 0.919500\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,epochs+1):\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a508d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 26 20:05:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.64       Driver Version: 471.80       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   56C    P8    N/A /  N/A |    895MiB /  2048MiB |    ERR!      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi -i 0\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 模型保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
